@inproceedings{lelidec2024raisim,
  author      = {Le Lidec, Quentin and Carpentier, Justin},
  title       = {Reconciling RaiSim with the Maximum Dissipation Principle},
  url         = {https://hal.science/hal-04067291},
  pdf         = {https://hal.science/hal-04438175/document},
  booktitle   = {IEEE Transactions on Robotics},
  year        = {2024},
  address     = {},
  month       = {January},
  doi         = {},
  abstract    = {Recent progress in reinforcement learning (RL) in robotics has been obtained by training control policy directly in simulation. Particularly in the context of quadrupedal locomotion, astonishing locomotion policies depicting high robustness against environmental perturbations have been trained by leveraging RaiSim simulator. While being more realistic than its counterparts, it has been shown recently that RaiSim does not obey the maximum dissipation principle, a fundamental principle when simulating rigid contact interactions. In this note, we detail these relaxations and propose an algorithmic correction of the RaiSim contact algorithm to handle the maximum dissipation principle adequately. Our experiments empirically demonstrate our approach leads to more physically-consistent simulation.  }
}
