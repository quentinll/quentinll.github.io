@article{lelidec2021randomized,
  title={{Leveraging randomized smoothing for optimal control of nonsmooth dynamical systems}},
  author={Le Lidec, Quentin and Schramm, Fabian and Montaut, Louis and Schmid, Cordelia and Laptev, Ivan and Carpentier, Justin},
  journal={Nonlinear Analysis: Hybrid Systems},
  volume={52},
  pages={101468},
  year={2021},
  month       = Dec,
  url         = {https://hal.archives-ouvertes.fr/hal-03480419},
  pdf         = {https://arxiv.org/pdf/2203.03986.pdf},
  publisher={Elsevier},
  abstract    = {Optimal Control (OC) algorithms such as Differential Dynamic Programming (DDP) take advantage of the derivatives of the dynamics to efficiently control physical systems. Yet, in the presence of nonsmooth dynamical systems, such class of algorithms are likely to fail due, for instance, to the presence of discontinuities in the dynamics derivatives or because of non-informative gradient during the solving. On the contrary, Reinforcement Learning (RL) algorithms have shown better empirical results in scenarios exhibiting nonsmooth effects (contacts, frictions, etc). Our approach leverages recent works on Randomized Smoothing (RS) to tackle nonsmoothness issues commonly encountered in Optimal Control, and provides key insights on the interplay between RL and OC through the prism of RS methods. This naturally leads us to introduce the Randomized Differential Dynamic Programming (R-DDP) algorithm accounting for deterministic but non-smooth dynamics in a very sample-efficient way. The experiments demonstrate that our method is able to solve classic robotic problems with dry friction and frictional contacts, where classical OC algorithms are likely to fail and RL algorithms require in practice a prohibitive number of samples to find an optimal solution. }
}
